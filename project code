#BUS 462 Group Project - Codebase
#April 5, 2022
#Team E.Kappa:
  #Alexandra Michelle Widjanarka (301385083)
  #Alicia Chow (301362722)
  #Demitria Erin Adela (301384713)
  #Janet Liani Chandra (301384754)
  #Minahil Oonwala (201344932)
  #Simran Sharma (301360244)


#Academic integrity pledge: We pledge on our honor that we have neither received nor given unauthorized assistance on this deliverable.

#Clearing mem buffers
cat("\014")  #Clear Console
rm(list = ls(all.names = TRUE))# clear all
gc()
set.seed(42) #Set a seed to ensure repeatable random samples

#Libraries
require(data.table)
require(pastecs)
require(stargazer)
require(PerformanceAnalytics)
require(corrplot)
library(caret)
library(fastDummies)
library(dplyr)
library(ggplot2)

# Input data from GitHub
data <- fread("https://raw.githubusercontent.com/simransharma1114/bus462grouproject/main/credit%20data.csv")

# Remove NAs from dataset
colSums(is.na(data))
data <- na.omit(data)

#Change data type of variables to integers
data$checking_status <- as.integer(factor(data$checking_status, levels = c("'<0'","'0<=X<200'","'>=200'","'no checking'")))
data$credit_history <- as.integer(factor(data$credit_history, levels = c("'critical/other existing credit'", "'existing paid'",  "'delayed previously'", "'no credits/all paid'" ,"'all paid'" )))
data$purpose <- as.integer(factor(data$purpose, levels = c("'domestic appliance'","radio/tv","furniture/equipment","repairs","'used car'","'new car'","education","business","retraining","other"))) #assuming the order goes from the cheapest purchase to the most expensive purchase.
data$savings_status<- as.integer(factor(data$savings_status, levels = c("'no known savings'", "'<100'","'500<=X<1000'","'>=1000'","'100<=X<500'")))
data$employment <- as.integer(factor(data$employment, levels = c("unemployed","'<1'","'1<=X<4'","'4<=X<7'","'>=7'")))
data$personal_status <- as.integer(factor(data$personal_status, levels = c("'male single'","'female div/dep/mar'","'male div/sep'","'male mar/wid'")))
data$other_parties <- as.integer(factor(data$other_parties, levels = c("none","guarantor","'co applicant'")))
data$property_magnitude <- as.integer(factor(data$property_magnitude, levels = c("'real estate'","'life insurance'","'no known property'","car")))
data$other_payment_plans<- as.integer(factor(data$other_payment_plans, levels = c("none", "bank","stores")))
data$housing<- as.integer(factor(data$housing, levels = c("own", "'for free'","rent")))
data$job<- as.integer(factor(data$job, levels = c("skilled", "'unskilled resident'","'high qualif/self emp/mgmt'","'unemp/unskilled non res'")))
data$own_telephone<- as.integer(factor(data$own_telephone, levels = c("none","yes")))
data$foreign_worker<- as.integer(factor(data$foreign_worker, levels = c("yes","no")))
data$class<- as.integer(factor(data$class, levels = c("good","bad")))


#Q1 - What variables should be focused on while evaluating credit amount?
#Dependent Variable: Credit Amount
#Independent Variables: All variables from dataset

#To get the correlation chart of ALL variables.
chart.Correlation(data, histogram=TRUE, pch=19)

# OLS model 
m.OLS<-lm(credit_amount ~ ., data=data)

# Looking at the summary results from the OLS regression model
summary(m.OLS)
AIC(m.OLS)
stargazer(m.OLS,type="text")

#Stepwise Regression
model.step.OLS <- step(m.OLS) 

# Looking at the summary results from the Stepwise regression 
stargazer(m.OLS,model.step.OLS,type="text")
summary(model.step.OLS)
AIC(model.step.OLS)



#Q2 - How does the scale of purchases affect oneâ€™s credit amount? That is, are individuals more likely to pay off their credit or less likely when purchasing larger items (which may take longer to pay off)?
#Dependent Variable: Credit Amount
#Independent Variables: Purpose, Credit History, Duration, Property Magnitude, Housing, Telephone (assuming it is similar to a mobile device and will be quite expensive)

# Begin by subsetting our data with only the relevant variables (dependent and independent variables)
dataq2<-subset(data,select=c(purpose, credit_history,duration,property_magnitude,housing,own_telephone,credit_amount))

#To get the correlation chart of all variables & correlogram
chart.Correlation(dataq2, histogram=TRUE, pch=19)
cor_data<-cor(dataq2)
corrplot(cor_data, method="number", "upper")

# To analyze the data and answer our question, run the OLS model with all independent variables mentioned above & look at the summary results
OLSModel1 <- lm(credit_amount ~ purpose + credit_history + duration + property_magnitude + housing + own_telephone, data=dataq2)
summary(OLSModel1)
stargazer(OLSModel1,type="text")
AIC(OLSModel1)

# Visualize the relationship between the amount of credit an individual has/duration and the various purchasing habits (purpose)
plot(dataq2$purpose, dataq2$credit_amount, main="Purpose vs. Credit Amount", xlab = "Purpose", ylab = "Credit Amount")
plot(dataq2$purpose, dataq2$duration, main="Purpose vs. Duration", xlab = "Purpose", ylab = "Duration")
plot(dataq2$duration, dataq2$credit_amount, main="Duration vs. Credit Amount", xlab = "Duration", ylab = "Credit Amount")

# Based on the first OLS Model, duration is the most significant variable when analyzing one's credit amount
# For our question, we want to analyze how purchases impact an individual's credit amount, and whether duration plays a factor in this 
# We should find the interactions between duration and purpose, and duration and owning a phone. 

# Additionally, While housing has a high co-efficient, it has a low correlation with duration and credit amount, our independent variable
cor(dataq2$credit_amount,dataq2$housing)

# Create a variable that considers the interaction between purpose and duration
purpose_duration <- (dataq2$purpose*dataq2$duration)

#Create a variable that considers the interaction between own_telephone and duration
telephone_duration <- (dataq2$own_telephone*dataq2$duration)

#Now create an OLS model that considers BOTH these interactions to see which best explains credit amounts
OLSModel2 <- lm(credit_amount ~ property_magnitude + housing + purpose_duration + telephone_duration, data=dataq2)
summary(OLSModel2)
stargazer(OLSModel2, type="text")
AIC(OLSModel2)

# Run stargazer to compare the 2 models
stargazer(OLSModel1, OLSModel2, type="text")

# Based on the results, OLSModel2 is the better fitted model due to its lower adjusted r-squared. 
# Duration is also the best indicator of credit amount, whereas purchases do impact credit, but not a lot as we thought initially.


#Q3 - Given the loan/customer features, we want to predict the default on loans.
#Dependent Variable: Credit Amount
#Independent Variables: 
  #Loan features (purpose, installment commitment, property magnitude, duration)
  #Customer features (employment, age, housing, job, foreign worker, age, credit history, credit amount)

getwd()
setwd("/Users/minahiloonwala/Downloads")
data <- read.csv('credit_2022.csv', header =TRUE)

##Assigning bad credit and good credit
data$BAD = ifelse(data$class=='bad', 1, 0)

data$BAD

##Converting to factors
data$purpose = factor(data$purpose)
data$checking_status = factor(data$checking_status)
data$credit_history = factor(data$credit_history)
data$savings_status = factor(data$savings_status)
data$employment = factor(data$employment)
data$property_magnitude = factor(data$property_magnitude)
data$housing = factor(data$housing)
data$job  = factor(data$job)
data$foreign_worker = factor(data$foreign_worker)

## checking_status
ggplot(data = data, mapping = aes(x = checking_status, fill = class)) + geom_bar(position = 'stack')

##we see that some factors above have a higher number of defaults (Even proportionally)

#credit_history
ggplot(data = data, mapping = aes(x = credit_history, fill = class)) + geom_bar(position = 'stack')

#purpose
ggplot(data = data, mapping = aes(x = purpose, fill = class)) + geom_bar(position = 'fill') + labs(y = 'proportion') 

## education, new car and others have higher default rates


#own telephone

ggplot(data = data, mapping = aes(x = own_telephone, fill = class)) + geom_bar(position = 'fill') + labs(y = 'proportion') 
## does not explain much

ggplot(data = data, mapping = aes(x = employment, fill = class)) + geom_bar(position = 'dodge')  

## employment does not have a lot fo explanatory power, except that it tells us that newly hired persons have a higher default rate

# foreign worker
ggplot(data = data, mapping = aes(x = foreign_worker, fill = class)) + geom_bar(position = 'fill') + labs(y = 'proportion')

## foreign workers default more

ggplot(data = data, mapping = aes(x = credit_amount, fill = class)) + geom_density(alpha = 0.4)
## shows that smaller loans are easily paid and that there are more defaulters with high credit amounts

ggplot(data = data, mapping = aes(x = class, y = age)) + geom_boxplot()
# the distributions are not that different, however younger people tend to have a higher mean default rate

ggplot(data = data, mapping = aes(x = num_dependents, fill = class)) + geom_bar(position = 'fill') + labs(y = 'proportion')

# number of dependents does not explain anything

# time to check some interactions

# credit_amount and duration

ggplot(data, mapping = aes(x = duration,  y= credit_amount, color = class)) + geom_point() + geom_smooth(method = 'gam', se = FALSE)

## not too different

# credit amount and age
ggplot(data, mapping = aes(x = age,  y= credit_amount, color = class)) + geom_point() + geom_smooth(method = 'gam', se = FALSE)

## different distributions, therefore we should create an interaction variable

data$age_amount = data$age * data$credit_amount

data$age_amount

# experiment 1
AUC1 = c()
accuracy1 = c()
for (k in 1:5) {
  train_idx = createDataPartition(data$class, p = 0.85, list = FALSE)
  df_train = data[train_idx,]
  df_test = data[-train_idx,]
  model <- glm(BAD ~ checking_status + duration + credit_history + credit_amount + purpose + credit_amount +
                 installment_commitment + property_magnitude +
                 age + employment +  housing + job + foreign_worker + age_amount, data = df_train,
               family = binomial(link = 'logit'))
  glm_probs = predict(model, newdata = df_test, type = 'response', se.fit = TRUE)
  
  predictions = ifelse(glm_probs$fit > 0.5, 1, 0)
  
  accuracy1 = c(accuracy1, sum(df_test$BAD == predictions)/length(predictions))
  
  ## AUC is a ranking measure 
  AUC1 = c(AUC1,ModelMetrics::auc(actual = df_test$BAD, predicted = as.numeric(glm_probs$fit)))
  
}
nrow(df_test)
predictions


mean(accuracy1)
mean(AUC1)

#prob(BAD) = y = f(age + a.....)
# the function in experiment one is estimated via logistic regression
# the function in experiment three is estimated via CART



# experiment 2: checking how AUC and accuracy change with the size of training set

set.seed(123)
AUC2 = c()
accuracy2 = c()
for (p in c(0.6, 0.65, 0.7, 0.75,0.77, 0.8, 0.83, 0.85, 0.9, 0.91, 0.93, 0.95)) {
  train_idx = createDataPartition(data$class, p = p, list = FALSE)
  df_train = data[train_idx,]
  df_test = data[-train_idx,]
  logit <- glm(BAD ~ checking_status + duration + credit_history + credit_amount + purpose + credit_amount +
                 installment_commitment + property_magnitude +
                 age + employment +  housing + job + foreign_worker + age_amount, data = df_train,
               family = binomial(link = 'logit'))
  glm_probs = predict(logit, newdata = df_test, type = 'response', se.fit = TRUE)
  
  predictions = ifelse(glm_probs$fit > 0.6, 1, 0)
  
  accuracy2 = c(accuracy2, sum(df_test$BAD == predictions)/length(predictions))
  
  ## AUC is a ranking measure 
  AUC2 = c(AUC2,ModelMetrics::auc(actual = df_test$BAD, predicted = as.numeric(glm_probs$fit)))
  
}


p_auc_acc = data.frame('p' = c(0.6, 0.65, 0.7, 0.75, 0.77, 0.8, 0.83, 0.85, 0.9, 0.91, 0.93, 0.95), 'auc' = AUC2, 'accuracy' = accuracy2)
ggplot(data = p_auc_acc, mapping = aes(x=p, y = auc)) + geom_smooth()
ggplot(data = p_auc_acc, mapping = aes(x=p, y = accuracy)) + geom_smooth()


# experiment 3: can CART do better?


set.seed(123)
auc3 = c()
for (p in c(0.6, 0.65, 0.7, 0.75,0.77, 0.8, 0.83, 0.85, 0.9, 0.91, 0.93, 0.95)) {
  train_idx = createDataPartition(data$class, p =p, list = FALSE)
  df_train = data[train_idx,]
  df_test = data[-train_idx,]
  cart <- rpart::rpart(BAD ~ checking_status + duration + credit_history + credit_amount + purpose + credit_amount +
                         installment_commitment + property_magnitude +
                         age + employment +  housing + job + foreign_worker + age_amount, data = df_train, method = 'class', minbucket = 10)
  
  
  predictions_CART = predict(cart, newdata = df_test, type = 'prob')
  
  auc3 = c(auc3, ModelMetrics::auc(actual = df_test$BAD, predicted = predictions_CART[,2]))
  
}  

p_auc_acc$auc_cart = auc3

ggplot() + geom_smooth(data = p_auc_acc, mapping = aes(x=p, y = auc, col = 'auc_logit')) + geom_smooth(data = p_auc_acc, mapping = aes(x=p, y = auc_cart, col = 'auc_CART'))


## divide data set into train and test
## trained (both) models on train and tested them on test set (in terms of auc)
